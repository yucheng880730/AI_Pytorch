{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN1DM9AFcA3E8Iox/OFlxw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yucheng880730/AI_Pytorch/blob/main/AI_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "phP30pG6WM_k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "knEAyZm1BzvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "MTiCCEqw7xH1",
        "outputId": "4fbf1910-46ab-4c1f-d9d5-c4aff5b929e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-adaf92a2-7b75-4f13-915d-07cd15192594\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-adaf92a2-7b75-4f13-915d-07cd15192594\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train_all_0.csv to train_all_0.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "usecols = ['feature1','feature2', 'feature3', 'feature4', 'feature5','feature6'\n",
        "           ,'feature7','feature8','feature9','feature10','feature11','feature12','target']\n",
        "df = pd.read_csv('train_all_0.csv',names=usecols)\n",
        "df"
      ],
      "metadata": {
        "id": "ZE9zcNDh5ePv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "9d191e9d-a9af-4be7-c206-4f2da618d4bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n",
              "0   -0.002390 -0.002091  0.001010 -0.002171  0.000091  0.000114  0.000548   \n",
              "1   -0.002484 -0.002170  0.000752  0.000790  0.000086  0.000113  0.000554   \n",
              "2   -0.002752 -0.002469  0.000998  0.002989  0.000087  0.000114  0.000555   \n",
              "3   -0.002925 -0.002657  0.001240  0.003282  0.000092  0.000116  0.000563   \n",
              "4   -0.003050 -0.002783  0.001476  0.000550  0.000090  0.000116  0.000602   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "475 -0.001887 -0.001211  0.000661 -0.000645  0.001544  0.001539  0.000090   \n",
              "476 -0.001840 -0.001211  0.000724 -0.000030  0.001526  0.001546  0.000089   \n",
              "477 -0.002028 -0.001431  0.000122  0.002421  0.001551  0.001550  0.000089   \n",
              "478 -0.001761 -0.001289  0.000528  0.000795  0.001549  0.001558  0.000090   \n",
              "479 -0.001698 -0.001352  0.000317  0.000710  0.001572  0.001572  0.000102   \n",
              "\n",
              "     feature8  feature9  feature10  feature11  feature12  target  \n",
              "0    0.000718  0.000021   0.000004   0.001011   0.000984       0  \n",
              "1    0.000679  0.000020   0.000003   0.001013   0.000981       0  \n",
              "2    0.000621  0.000021   0.000004   0.001038   0.000988       0  \n",
              "3    0.000485  0.000026   0.000006   0.001069   0.001009       1  \n",
              "4    0.000446  0.000026   0.000007   0.001051   0.001009       1  \n",
              "..        ...       ...        ...        ...        ...     ...  \n",
              "475  0.000369  0.001451   0.000685   0.001134   0.001385       1  \n",
              "476  0.000272  0.001480   0.000644   0.001229   0.001433       1  \n",
              "477  0.000233  0.001513   0.000688   0.001356   0.001481       1  \n",
              "478  0.000233  0.001557   0.000923   0.001439   0.001572       1  \n",
              "479  0.000252  0.001572   0.000633   0.001285   0.001546       1  \n",
              "\n",
              "[480 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b11ecbe-8777-4492-9927-eac0bbbcc660\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature1</th>\n",
              "      <th>feature2</th>\n",
              "      <th>feature3</th>\n",
              "      <th>feature4</th>\n",
              "      <th>feature5</th>\n",
              "      <th>feature6</th>\n",
              "      <th>feature7</th>\n",
              "      <th>feature8</th>\n",
              "      <th>feature9</th>\n",
              "      <th>feature10</th>\n",
              "      <th>feature11</th>\n",
              "      <th>feature12</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.002390</td>\n",
              "      <td>-0.002091</td>\n",
              "      <td>0.001010</td>\n",
              "      <td>-0.002171</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.000548</td>\n",
              "      <td>0.000718</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.001011</td>\n",
              "      <td>0.000984</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.002484</td>\n",
              "      <td>-0.002170</td>\n",
              "      <td>0.000752</td>\n",
              "      <td>0.000790</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.000113</td>\n",
              "      <td>0.000554</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.000981</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.002752</td>\n",
              "      <td>-0.002469</td>\n",
              "      <td>0.000998</td>\n",
              "      <td>0.002989</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>0.000114</td>\n",
              "      <td>0.000555</td>\n",
              "      <td>0.000621</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.001038</td>\n",
              "      <td>0.000988</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.002925</td>\n",
              "      <td>-0.002657</td>\n",
              "      <td>0.001240</td>\n",
              "      <td>0.003282</td>\n",
              "      <td>0.000092</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000563</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.001069</td>\n",
              "      <td>0.001009</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.003050</td>\n",
              "      <td>-0.002783</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>0.000602</td>\n",
              "      <td>0.000446</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.001051</td>\n",
              "      <td>0.001009</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>-0.001887</td>\n",
              "      <td>-0.001211</td>\n",
              "      <td>0.000661</td>\n",
              "      <td>-0.000645</td>\n",
              "      <td>0.001544</td>\n",
              "      <td>0.001539</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.001451</td>\n",
              "      <td>0.000685</td>\n",
              "      <td>0.001134</td>\n",
              "      <td>0.001385</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>-0.001840</td>\n",
              "      <td>-0.001211</td>\n",
              "      <td>0.000724</td>\n",
              "      <td>-0.000030</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>0.001546</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.001480</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>0.001229</td>\n",
              "      <td>0.001433</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>-0.002028</td>\n",
              "      <td>-0.001431</td>\n",
              "      <td>0.000122</td>\n",
              "      <td>0.002421</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>0.001550</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.001513</td>\n",
              "      <td>0.000688</td>\n",
              "      <td>0.001356</td>\n",
              "      <td>0.001481</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>-0.001761</td>\n",
              "      <td>-0.001289</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.000795</td>\n",
              "      <td>0.001549</td>\n",
              "      <td>0.001558</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.001557</td>\n",
              "      <td>0.000923</td>\n",
              "      <td>0.001439</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>-0.001698</td>\n",
              "      <td>-0.001352</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.000710</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.000252</td>\n",
              "      <td>0.001572</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>0.001285</td>\n",
              "      <td>0.001546</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>480 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b11ecbe-8777-4492-9927-eac0bbbcc660')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b11ecbe-8777-4492-9927-eac0bbbcc660 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b11ecbe-8777-4492-9927-eac0bbbcc660');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create tensor from df\n",
        "torch_tensor = torch.tensor(df.values)\n",
        "torch_tensor"
      ],
      "metadata": {
        "id": "AdhylgA68N-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d6c975-cc93-490a-fb9d-73fa000d9179"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3899e-03, -2.0912e-03,  1.0095e-03,  ...,  1.0108e-03,\n",
              "          9.8368e-04,  0.0000e+00],\n",
              "        [-2.4843e-03, -2.1698e-03,  7.5231e-04,  ...,  1.0131e-03,\n",
              "          9.8069e-04,  0.0000e+00],\n",
              "        [-2.7516e-03, -2.4686e-03,  9.9830e-04,  ...,  1.0382e-03,\n",
              "          9.8835e-04,  0.0000e+00],\n",
              "        ...,\n",
              "        [-2.0283e-03, -1.4308e-03,  1.2189e-04,  ...,  1.3561e-03,\n",
              "          1.4813e-03,  1.0000e+00],\n",
              "        [-1.7610e-03, -1.2893e-03,  5.2797e-04,  ...,  1.4390e-03,\n",
              "          1.5723e-03,  1.0000e+00],\n",
              "        [-1.6981e-03, -1.3522e-03,  3.1712e-04,  ...,  1.2852e-03,\n",
              "          1.5457e-03,  1.0000e+00]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch_tensor.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os5y16Om-Ffm",
        "outputId": "434a122a-8baf-4326-8a3b-d6609504f2e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([480, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "JV7b-ngkBlmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delete last column\n",
        "feature_tensor = torch_tensor[:,:-1]\n",
        "target_tensor = torch_tensor[:,-1]\n",
        "feature_tensor.size(), target_tensor.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnzDUe89-LB9",
        "outputId": "51eca6e0-af2e-45f8-dd56-f40de4c734e1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([480, 12]), torch.Size([480]))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X,valid_X,test_X = torch.split(feature_tensor, [384,48,48])\n",
        "train_y,valid_y,test_y = torch.split(target_tensor, [384,48,48])\n",
        "print(train_X.size(),valid_X.size(),test_X.size())\n",
        "print(train_y.size(),valid_y.size(),test_y.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOXy2H0qEJeS",
        "outputId": "0e6a12fc-a01f-4c2d-ec1b-57ffaeadef83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([384, 12]) torch.Size([48, 12]) torch.Size([48, 12])\n",
            "torch.Size([384]) torch.Size([48]) torch.Size([48])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NkE3UrG07ES_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "Qu6forc_GdH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KNN(train_X,train_y, test_X, test_y, k):\n",
        "\n",
        "  # n = 384 m = 96 \n",
        "  n = train_X.size(0)\n",
        "  m = test_X.size(0)  \n",
        "\n",
        "  # caculate distance\n",
        "  xx = (test_X**2).sum(dim=1, keepdim=True).expand(m, n)\n",
        "  yy = (train_X**2).sum(dim=1, keepdim=True).expand(n, m).transpose(0,1)\n",
        "\n",
        "  dist_mat = xx + yy - 2*test_X.matmul(train_X.transpose(0,1))\n",
        "  dist_mat = dist_mat.argsort(dim=-1)\n",
        "  # print(f'dist_mat.shape = {dist_mat.shape}')\n",
        "\n",
        "  res = []\n",
        "  for idxs in dist_mat:\n",
        "    # print(np.array([train_y[idx] for idx in idxs[:k]], dtype = \"int\"))\n",
        "    # print(np.bincount(np.array([train_y[idx] for idx in idxs[:k]], dtype = \"int\")))\n",
        "    res.append(np.bincount(np.array([train_y[idx] for idx in idxs[:k]], dtype = \"int\")).argmax())\n",
        "\n",
        "  \n",
        "  assert len(res) == len(test_y)\n",
        "  print(\"k = %d, acc = %f: \"%(k, np.mean(np.array(test_y) == res)))"
      ],
      "metadata": {
        "id": "c-jvR3DCGhiK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(2,50):\n",
        "    a = KNN(train_X, train_y, test_X, test_y, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9RxRhiCHsBJ",
        "outputId": "584a275f-e663-4d3e-b8c8-472e9f43c636"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 2, acc = 0.458333: \n",
            "k = 3, acc = 0.625000: \n",
            "k = 4, acc = 0.604167: \n",
            "k = 5, acc = 0.666667: \n",
            "k = 6, acc = 0.583333: \n",
            "k = 7, acc = 0.666667: \n",
            "k = 8, acc = 0.645833: \n",
            "k = 9, acc = 0.666667: \n",
            "k = 10, acc = 0.625000: \n",
            "k = 11, acc = 0.666667: \n",
            "k = 12, acc = 0.625000: \n",
            "k = 13, acc = 0.645833: \n",
            "k = 14, acc = 0.604167: \n",
            "k = 15, acc = 0.645833: \n",
            "k = 16, acc = 0.625000: \n",
            "k = 17, acc = 0.666667: \n",
            "k = 18, acc = 0.625000: \n",
            "k = 19, acc = 0.666667: \n",
            "k = 20, acc = 0.625000: \n",
            "k = 21, acc = 0.729167: \n",
            "k = 22, acc = 0.708333: \n",
            "k = 23, acc = 0.729167: \n",
            "k = 24, acc = 0.708333: \n",
            "k = 25, acc = 0.750000: \n",
            "k = 26, acc = 0.729167: \n",
            "k = 27, acc = 0.750000: \n",
            "k = 28, acc = 0.750000: \n",
            "k = 29, acc = 0.854167: \n",
            "k = 30, acc = 0.833333: \n",
            "k = 31, acc = 0.854167: \n",
            "k = 32, acc = 0.854167: \n",
            "k = 33, acc = 0.895833: \n",
            "k = 34, acc = 0.895833: \n",
            "k = 35, acc = 0.895833: \n",
            "k = 36, acc = 0.895833: \n",
            "k = 37, acc = 0.916667: \n",
            "k = 38, acc = 0.916667: \n",
            "k = 39, acc = 0.958333: \n",
            "k = 40, acc = 0.937500: \n",
            "k = 41, acc = 0.979167: \n",
            "k = 42, acc = 0.979167: \n",
            "k = 43, acc = 1.000000: \n",
            "k = 44, acc = 1.000000: \n",
            "k = 45, acc = 1.000000: \n",
            "k = 46, acc = 1.000000: \n",
            "k = 47, acc = 1.000000: \n",
            "k = 48, acc = 1.000000: \n",
            "k = 49, acc = 1.000000: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8SWLchC67Yz7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training_Function\n",
        "function for SVM, Softmax, Two-layer neural network classifier\n"
      ],
      "metadata": {
        "id": "GaZRLUnhiZSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_function(epochs, optimizer, model, loss_fn, train_X, valid_X, \n",
        "                  train_y, valid_y):\n",
        "    validatation_loss = []\n",
        "    for epoch in range(epochs + 1):\n",
        "      \n",
        "        train_X_predict = model(train_X.float())        \n",
        "        loss_train = loss_fn(train_X_predict, train_y)\n",
        "\n",
        "        valid_X_predict = model(valid_X.float())\n",
        "        loss_valid = loss_fn(valid_X_predict, valid_y)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch == 1 or epoch % 100 == 0:\n",
        "            \n",
        "            output_test = (train_X_predict > 0.5).float()\n",
        "            output_valid = (valid_X_predict>0.5).float()\n",
        "\n",
        "            correct_test = (output_test == train_y).float().sum()\n",
        "            correct_test = correct_test/train_X.shape[0]\n",
        "\n",
        "            correct_valid = (output_valid == valid_y).float().sum()\n",
        "            correct_valid = correct_valid/valid_X.shape[0]\n",
        "\n",
        "            validatation_loss.append(loss_valid.item())\n",
        "            print(f\"Epoch {epoch}, Training loss {loss_train.item():.4f},\"\n",
        "                  f\" Validation loss {loss_valid.item():.4f}\")\n",
        "\n",
        "            print(\"train acc is %f\"%(correct_test))\n",
        "            print(\"valid acc is %f\"%(correct_valid))\n",
        "\n",
        "\n",
        "    plt.plot(validatation_loss)\n",
        "    plt.xlabel('Iteration number')\n",
        "    plt.ylabel('Loss value')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "w1pVTBBdCk53"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizer\n",
        "using SGD"
      ],
      "metadata": {
        "id": "nfJQStcPE55e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimizer(model):\n",
        "  optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
        "  return optimizer"
      ],
      "metadata": {
        "id": "WvghBfBTD9AP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Change Type\n",
        "from double to float"
      ],
      "metadata": {
        "id": "MwUR2q1rNfZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_X.float()\n",
        "train_y = train_y.float()\n",
        "print(train_X.type())\n",
        "print(train_y.type())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXFet7LcMV62",
        "outputId": "2e3555b6-a98c-42c6-dc0e-4575bbc6f223"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.FloatTensor\n",
            "torch.FloatTensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SLe72AMHLy_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PKjymiElrOXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "SVM = nn.Sequential(\n",
        "            nn.Linear(12,2), \n",
        "            )\n",
        "model_SVM = SVM"
      ],
      "metadata": {
        "id": "k7wW3CfaCcyG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Loss Function"
      ],
      "metadata": {
        "id": "X1F7YVR_40bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hinge_loss(train_X_predict, train_y): \n",
        "    \n",
        "    # define loss function\n",
        "    labels = train_y.numpy().astype(int)\n",
        "    num_labels = len(train_y) #384\n",
        "    corrects = train_X_predict[range(num_labels), labels].unsqueeze(0).T\n",
        "    corrects = corrects.unsqueeze(0)\n",
        "    \n",
        "    # 最大間隔\n",
        "    margin = 1.0\n",
        "    margins = train_X_predict - corrects + margin\n",
        "    loss = torch.sum(torch.max(margins, 1)[0]) / len(train_y)\n",
        "\n",
        "    # 正則化强度\n",
        "    # reg = 1e-3\n",
        "    # loss += reg * torch.sum(weight ** 2)\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "aNrztFitCjhE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_function(\n",
        "    epochs = 2000, \n",
        "    optimizer = optimizer(model_SVM),\n",
        "    model = model_SVM,\n",
        "    loss_fn = hinge_loss, \n",
        "    train_X = train_X,\n",
        "    train_y = train_y.unsqueeze(1) ,\n",
        "    valid_X = valid_X,\n",
        "    valid_y = valid_y.unsqueeze(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9_Qlln9kCpxV",
        "outputId": "7a3347ea-f389-4bc5-e2fc-6d1a9a7097af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Training loss 2.1514, Validation loss 2.2076\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 1, Training loss 2.1509, Validation loss 2.2068\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 100, Training loss 2.0927, Validation loss 2.1263\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 200, Training loss 2.0340, Validation loss 2.0451\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 300, Training loss 1.9753, Validation loss 1.9638\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 400, Training loss 1.9167, Validation loss 1.8826\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 500, Training loss 1.8580, Validation loss 1.8013\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 600, Training loss 1.7993, Validation loss 1.7201\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 700, Training loss 1.7406, Validation loss 1.6388\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 800, Training loss 1.6819, Validation loss 1.5576\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 900, Training loss 1.6232, Validation loss 1.4763\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 1000, Training loss 1.5645, Validation loss 1.3951\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 1100, Training loss 1.5058, Validation loss 1.3138\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 1200, Training loss 1.4471, Validation loss 1.2326\n",
            "train acc is 0.458333\n",
            "valid acc is 0.250000\n",
            "Epoch 1300, Training loss 1.3884, Validation loss 1.1513\n",
            "train acc is 1.000000\n",
            "valid acc is 1.000000\n",
            "Epoch 1400, Training loss 1.3297, Validation loss 1.0700\n",
            "train acc is 1.000000\n",
            "valid acc is 1.000000\n",
            "Epoch 1500, Training loss 1.2710, Validation loss 0.9888\n",
            "train acc is 1.000000\n",
            "valid acc is 1.000000\n",
            "Epoch 1600, Training loss 1.2123, Validation loss 0.9075\n",
            "train acc is 1.000000\n",
            "valid acc is 1.000000\n",
            "Epoch 1700, Training loss 1.1536, Validation loss 0.8263\n",
            "train acc is 1.000000\n",
            "valid acc is 1.000000\n",
            "Epoch 1800, Training loss 1.0949, Validation loss 0.7450\n",
            "train acc is 1.000000\n",
            "valid acc is 1.000000\n",
            "Epoch 1900, Training loss 1.0362, Validation loss 0.6638\n",
            "train acc is 1.000000\n",
            "valid acc is 1.000000\n",
            "Epoch 2000, Training loss 0.9775, Validation loss 0.5825\n",
            "train acc is 1.000000\n",
            "valid acc is 1.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predict = model_SVM(test_X.float())\n",
        "output_test = (test_predict>0.5).float()\n",
        "test_SVM = test_y.unsqueeze(1)\n",
        "\n",
        "correctSVM = (output_test == test_SVM).float().sum()\n",
        "print(correctSVM)\n",
        "\n",
        "correctSVM = correctSVM / test_X.shape[0]\n",
        "print(\"test acc is %f\"%(correctSVM))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb-oCgiSCtFM",
        "outputId": "d3147360-f058-41db-8bac-6cec92ad88d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(48.)\n",
            "test acc is 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(a.validatation_loss)\n",
        "plt.xlabel('Iteration number')\n",
        "plt.ylabel('Loss value')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "Ok4LROgcV43V",
        "outputId": "cc008f5d-a2df-40fc-af2e-02189cb7545a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-190-2b09e518e93d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidatation_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration number'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'validatation_loss'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-robMV4f7iKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SoftMax"
      ],
      "metadata": {
        "id": "sAZKjZTTbtfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Softmax = nn.Sequential(\n",
        "            nn.Linear(12,1), \n",
        "            nn.Softmax(dim=1))\n",
        "model_Softmax = Softmax"
      ],
      "metadata": {
        "id": "_NgzHuPTbx5L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_function(\n",
        "    epochs = 18000, \n",
        "    optimizer = optimizer(model_Softmax),\n",
        "    model = model_Softmax,\n",
        "    loss_fn = nn.BCEWithLogitsLoss(), \n",
        "    train_X = train_X,\n",
        "    train_y = train_y.unsqueeze(1) ,\n",
        "    valid_X = valid_X,\n",
        "    valid_y = valid_y.unsqueeze(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jhh389sbfnB7",
        "outputId": "3e67c756-3566-400b-aa4e-4bc4c4076cf3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 1900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17100, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17200, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17300, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17400, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17500, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17600, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17700, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17800, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17900, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 18000, Training loss 0.5424, Validation loss 0.4383\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y_predict = model_Softmax(test_X.float())\n",
        "output_t = (test_y_predict>0.5).float()\n",
        "test_Softmax = test_y.unsqueeze(1)\n",
        "correct_Softmax = (output_t == test_Softmax).float().sum()\n",
        "print(correct_Softmax)\n",
        "correct_Softmax = correct_Softmax/test_X.shape[0]\n",
        "print(\"test acc is %f\"%(correct_Softmax))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCTBhAwLfqB6",
        "outputId": "6306358a-fd80-4045-ac38-40c549d708d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(48.)\n",
            "test acc is 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "t4Y8xVls7nLZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Two-layer neural network classifier"
      ],
      "metadata": {
        "id": "t7at9aSD75SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Two_layer = nn.Sequential(\n",
        "            nn.Linear(12,36), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(36,1))\n",
        "model_Twolayer = Two_layer"
      ],
      "metadata": {
        "id": "Gldq9LWvftN-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_function(\n",
        "    epochs = 18000, \n",
        "    optimizer = optimizer(model_Twolayer),\n",
        "    model = model_Twolayer,\n",
        "    loss_fn = nn.BCEWithLogitsLoss(), \n",
        "    train_X = train_X,\n",
        "    train_y = train_y.unsqueeze(1) ,\n",
        "    valid_X = valid_X,\n",
        "    valid_y = valid_y.unsqueeze(1))"
      ],
      "metadata": {
        "id": "ExXSPpC87-N-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13f4a79c-45be-4ffa-ed4d-3c47333a702c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Training loss 0.7531, Validation loss 0.7741\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1, Training loss 0.7529, Validation loss 0.7739\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 100, Training loss 0.7378, Validation loss 0.7538\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 200, Training loss 0.7237, Validation loss 0.7349\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 300, Training loss 0.7106, Validation loss 0.7172\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 400, Training loss 0.6986, Validation loss 0.7006\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 500, Training loss 0.6874, Validation loss 0.6852\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 600, Training loss 0.6770, Validation loss 0.6706\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 700, Training loss 0.6674, Validation loss 0.6570\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 800, Training loss 0.6585, Validation loss 0.6442\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 900, Training loss 0.6502, Validation loss 0.6322\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1000, Training loss 0.6424, Validation loss 0.6209\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1100, Training loss 0.6353, Validation loss 0.6102\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1200, Training loss 0.6286, Validation loss 0.6002\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1300, Training loss 0.6224, Validation loss 0.5907\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1400, Training loss 0.6166, Validation loss 0.5818\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1500, Training loss 0.6112, Validation loss 0.5733\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1600, Training loss 0.6061, Validation loss 0.5653\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1700, Training loss 0.6015, Validation loss 0.5578\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1800, Training loss 0.5971, Validation loss 0.5507\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 1900, Training loss 0.5930, Validation loss 0.5439\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 2000, Training loss 0.5892, Validation loss 0.5376\n",
            "train acc is 0.229167\n",
            "valid acc is 0.125000\n",
            "Epoch 2100, Training loss 0.5857, Validation loss 0.5315\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2200, Training loss 0.5824, Validation loss 0.5258\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2300, Training loss 0.5794, Validation loss 0.5204\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2400, Training loss 0.5765, Validation loss 0.5152\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2500, Training loss 0.5738, Validation loss 0.5104\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2600, Training loss 0.5714, Validation loss 0.5058\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2700, Training loss 0.5690, Validation loss 0.5014\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2800, Training loss 0.5669, Validation loss 0.4972\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 2900, Training loss 0.5649, Validation loss 0.4933\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3000, Training loss 0.5630, Validation loss 0.4895\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3100, Training loss 0.5613, Validation loss 0.4860\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3200, Training loss 0.5597, Validation loss 0.4826\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3300, Training loss 0.5582, Validation loss 0.4794\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3400, Training loss 0.5568, Validation loss 0.4763\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3500, Training loss 0.5555, Validation loss 0.4734\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3600, Training loss 0.5542, Validation loss 0.4707\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3700, Training loss 0.5531, Validation loss 0.4680\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3800, Training loss 0.5521, Validation loss 0.4655\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 3900, Training loss 0.5511, Validation loss 0.4632\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4000, Training loss 0.5502, Validation loss 0.4609\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4100, Training loss 0.5493, Validation loss 0.4588\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4200, Training loss 0.5485, Validation loss 0.4567\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4300, Training loss 0.5478, Validation loss 0.4548\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4400, Training loss 0.5471, Validation loss 0.4529\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4500, Training loss 0.5465, Validation loss 0.4511\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4600, Training loss 0.5459, Validation loss 0.4495\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4700, Training loss 0.5454, Validation loss 0.4479\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4800, Training loss 0.5449, Validation loss 0.4463\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 4900, Training loss 0.5444, Validation loss 0.4449\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5000, Training loss 0.5440, Validation loss 0.4435\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5100, Training loss 0.5435, Validation loss 0.4421\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5200, Training loss 0.5432, Validation loss 0.4409\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5300, Training loss 0.5428, Validation loss 0.4396\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5400, Training loss 0.5425, Validation loss 0.4385\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5500, Training loss 0.5422, Validation loss 0.4374\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5600, Training loss 0.5419, Validation loss 0.4363\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5700, Training loss 0.5416, Validation loss 0.4353\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5800, Training loss 0.5414, Validation loss 0.4343\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 5900, Training loss 0.5412, Validation loss 0.4334\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6000, Training loss 0.5410, Validation loss 0.4325\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6100, Training loss 0.5408, Validation loss 0.4317\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6200, Training loss 0.5406, Validation loss 0.4309\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6300, Training loss 0.5404, Validation loss 0.4301\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6400, Training loss 0.5403, Validation loss 0.4294\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6500, Training loss 0.5401, Validation loss 0.4287\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6600, Training loss 0.5400, Validation loss 0.4280\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6700, Training loss 0.5399, Validation loss 0.4273\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6800, Training loss 0.5397, Validation loss 0.4267\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 6900, Training loss 0.5396, Validation loss 0.4261\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7000, Training loss 0.5395, Validation loss 0.4256\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7100, Training loss 0.5394, Validation loss 0.4250\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7200, Training loss 0.5394, Validation loss 0.4245\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7300, Training loss 0.5393, Validation loss 0.4240\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7400, Training loss 0.5392, Validation loss 0.4235\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7500, Training loss 0.5391, Validation loss 0.4231\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7600, Training loss 0.5391, Validation loss 0.4226\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7700, Training loss 0.5390, Validation loss 0.4222\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7800, Training loss 0.5390, Validation loss 0.4218\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 7900, Training loss 0.5389, Validation loss 0.4214\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8000, Training loss 0.5389, Validation loss 0.4210\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8100, Training loss 0.5388, Validation loss 0.4207\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8200, Training loss 0.5388, Validation loss 0.4203\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8300, Training loss 0.5387, Validation loss 0.4200\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8400, Training loss 0.5387, Validation loss 0.4197\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8500, Training loss 0.5387, Validation loss 0.4194\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8600, Training loss 0.5386, Validation loss 0.4191\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8700, Training loss 0.5386, Validation loss 0.4188\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8800, Training loss 0.5386, Validation loss 0.4185\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 8900, Training loss 0.5386, Validation loss 0.4183\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9000, Training loss 0.5385, Validation loss 0.4180\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9100, Training loss 0.5385, Validation loss 0.4178\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9200, Training loss 0.5385, Validation loss 0.4176\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9300, Training loss 0.5385, Validation loss 0.4174\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9400, Training loss 0.5385, Validation loss 0.4172\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9500, Training loss 0.5385, Validation loss 0.4170\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9600, Training loss 0.5384, Validation loss 0.4168\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9700, Training loss 0.5384, Validation loss 0.4166\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9800, Training loss 0.5384, Validation loss 0.4164\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 9900, Training loss 0.5384, Validation loss 0.4162\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10000, Training loss 0.5384, Validation loss 0.4161\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10100, Training loss 0.5384, Validation loss 0.4159\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10200, Training loss 0.5384, Validation loss 0.4157\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10300, Training loss 0.5384, Validation loss 0.4156\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10400, Training loss 0.5384, Validation loss 0.4155\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10500, Training loss 0.5384, Validation loss 0.4153\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10600, Training loss 0.5383, Validation loss 0.4152\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10700, Training loss 0.5383, Validation loss 0.4151\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10800, Training loss 0.5383, Validation loss 0.4150\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 10900, Training loss 0.5383, Validation loss 0.4148\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11000, Training loss 0.5383, Validation loss 0.4147\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11100, Training loss 0.5383, Validation loss 0.4146\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11200, Training loss 0.5383, Validation loss 0.4145\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11300, Training loss 0.5383, Validation loss 0.4144\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11400, Training loss 0.5383, Validation loss 0.4143\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11500, Training loss 0.5383, Validation loss 0.4142\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11600, Training loss 0.5383, Validation loss 0.4141\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11700, Training loss 0.5383, Validation loss 0.4141\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11800, Training loss 0.5383, Validation loss 0.4140\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 11900, Training loss 0.5383, Validation loss 0.4139\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12000, Training loss 0.5383, Validation loss 0.4138\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12100, Training loss 0.5383, Validation loss 0.4138\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12200, Training loss 0.5383, Validation loss 0.4137\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12300, Training loss 0.5383, Validation loss 0.4136\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12400, Training loss 0.5383, Validation loss 0.4136\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12500, Training loss 0.5383, Validation loss 0.4135\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12600, Training loss 0.5383, Validation loss 0.4134\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12700, Training loss 0.5383, Validation loss 0.4134\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12800, Training loss 0.5383, Validation loss 0.4133\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 12900, Training loss 0.5383, Validation loss 0.4133\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13000, Training loss 0.5383, Validation loss 0.4132\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13100, Training loss 0.5383, Validation loss 0.4132\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13200, Training loss 0.5383, Validation loss 0.4131\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13300, Training loss 0.5383, Validation loss 0.4131\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13400, Training loss 0.5383, Validation loss 0.4130\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13500, Training loss 0.5383, Validation loss 0.4130\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13600, Training loss 0.5383, Validation loss 0.4129\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13700, Training loss 0.5383, Validation loss 0.4129\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13800, Training loss 0.5383, Validation loss 0.4129\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 13900, Training loss 0.5383, Validation loss 0.4128\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14000, Training loss 0.5383, Validation loss 0.4128\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14100, Training loss 0.5383, Validation loss 0.4128\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14200, Training loss 0.5383, Validation loss 0.4127\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14300, Training loss 0.5383, Validation loss 0.4127\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14400, Training loss 0.5383, Validation loss 0.4127\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14500, Training loss 0.5383, Validation loss 0.4126\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14600, Training loss 0.5383, Validation loss 0.4126\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14700, Training loss 0.5383, Validation loss 0.4126\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14800, Training loss 0.5383, Validation loss 0.4126\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 14900, Training loss 0.5383, Validation loss 0.4125\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15000, Training loss 0.5383, Validation loss 0.4125\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15100, Training loss 0.5383, Validation loss 0.4125\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15200, Training loss 0.5383, Validation loss 0.4125\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15300, Training loss 0.5383, Validation loss 0.4125\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15400, Training loss 0.5383, Validation loss 0.4124\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15500, Training loss 0.5383, Validation loss 0.4124\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15600, Training loss 0.5383, Validation loss 0.4124\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15700, Training loss 0.5383, Validation loss 0.4124\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15800, Training loss 0.5383, Validation loss 0.4124\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 15900, Training loss 0.5383, Validation loss 0.4123\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16000, Training loss 0.5383, Validation loss 0.4123\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16100, Training loss 0.5383, Validation loss 0.4123\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16200, Training loss 0.5383, Validation loss 0.4123\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16300, Training loss 0.5383, Validation loss 0.4123\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16400, Training loss 0.5383, Validation loss 0.4123\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16500, Training loss 0.5383, Validation loss 0.4123\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16600, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16700, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16800, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 16900, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17000, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17100, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17200, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17300, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17400, Training loss 0.5383, Validation loss 0.4122\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17500, Training loss 0.5383, Validation loss 0.4121\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17600, Training loss 0.5383, Validation loss 0.4121\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17700, Training loss 0.5383, Validation loss 0.4121\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17800, Training loss 0.5383, Validation loss 0.4121\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 17900, Training loss 0.5383, Validation loss 0.4121\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n",
            "Epoch 18000, Training loss 0.5383, Validation loss 0.4121\n",
            "train acc is 0.770833\n",
            "valid acc is 0.875000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxddZ3/8dcne5qtSbPQNm3TlVKgLA1lXwSBwijFQRHwN4Kjgv5EXEb94cz8hMGZ3+g4MuOCjugwIIqAuFVBNlllbYptofsKTWlpmm5pmmb9/P44J+UmvWlu2tycm5v388F53HO+5/s999OTkk/P+Z7z/Zq7IyIi0ltG1AGIiEhqUoIQEZG4lCBERCQuJQgREYlLCUJEROLKijqAwVJeXu41NTVRhyEiMqwsWrRou7tXxNuXNgmipqaGurq6qMMQERlWzOzNvvbpFpOIiMSlBCEiInEpQYiISFxKECIiEpcShIiIxKUEISIicSlBiIhIXGnzHsThau3o5DtPrmH0qGxqxhRw0bFHRR2SiEhKGPEJYve+dn703Ho6u4J5Mf78f95DdemoiKMSEYneiL/FVFmcx9p/uYSff+JUANZs2xtxRCIiqWHEJwgAM2PW2GIA1ilBiIgAShAHlBbkUFaQw7oGJQgREVCC6GFaRSFrdQUhIgIoQfQwtbKAdQ3NUYchIpISlCBiTK0oZEdzGzua26IORUQkckoQMaZWFgKoH0JEBCWIHqZVhAlC/RAiIkoQscaPzic3K0NXECIiJDlBmNk8M1tlZmvN7OY4+//DzBaHy2oz2xWzrzNm34JkxtktI8OYoieZRESAJA61YWaZwB3AhUA9sNDMFrj78u467v6FmPqfBU6KOUSLu5+YrPj6MrWigKX1u4f6a0VEUk4yryDmAmvdfb27twH3A/MPUf9q4BdJjCch0yoL2bRzH/vbO6MORUQkUslMEOOBTTHb9WHZQcxsEjAZeCqmOM/M6szsZTO7vI9214d16hoaGgYl6KkVhbjDhu16H0JERrZU6aS+CnjI3WP/2T7J3WuBa4D/NLOpvRu5+53uXuvutRUVFYMSyNQKPeoqIgLJTRCbgQkx29VhWTxX0ev2krtvDj/XA8/Qs38iaaZUFGCGOqpFZMRLZoJYCEw3s8lmlkOQBA56GsnMZgKlwEsxZaVmlhuulwNnAst7t02GvOxMqkvzNeSGiIx4SXuKyd07zOxG4DEgE7jL3ZeZ2W1Anbt3J4urgPvd3WOaHwP8yMy6CJLYN2Kffkq2qRWFellOREa8pM4o5+6PAI/0Kvtar+1b47R7ETg+mbEdyrSKQl5e30hXl5ORYVGFISISqVTppE4pUysL2d/exeZdLVGHIiISGSWIOPQkk4iIEkRc08JRXfUkk4iMZEoQcZQV5FBemMuqrU1RhyIiEhkliD4cM7aIlUoQIjKCKUH0YeZRRax+p4mOzq6oQxERiYQSRB9mHlVMa0cXGxv1wpyIjExKEH2YObYIgBVbdJtJREYmJYg+TKssJDPDWLl1T9ShiIhEQgmiD7lZmUytKGClriBEZIRSgjiEY8YW60kmERmxlCAOYeZRxWze1cLulvaoQxERGXJKEIfQ3VGtF+ZEZCRSgjiEY44qBlBHtYiMSEoQh1BVnMvoUdl61FVERiQliEMwM2YeVaQrCBEZkZQg+jHzqGJWbW2iq8v7rywikkaUIPpxzNgi9rV1smnnvqhDEREZUkoQ/ZgZdlSrH0JERpqkJggzm2dmq8xsrZndHGf/f5jZ4nBZbWa7YvZda2ZrwuXaZMZ5KDOqijDTk0wiMvJkJevAZpYJ3AFcCNQDC81sgbsv767j7l+Iqf9Z4KRwvQy4BagFHFgUtt2ZrHj7kp+TyeQxBazYogQhIiNLMq8g5gJr3X29u7cB9wPzD1H/auAX4frFwBPuviNMCk8A85IY6yEdM7aY5UoQIjLCJDNBjAc2xWzXh2UHMbNJwGTgqYG0NbPrzazOzOoaGhoGJeh4jq8uYdOOFnY2tyXtO0REUk2qdFJfBTzk7p0DaeTud7p7rbvXVlRUJCk0mD2+BIClm3cn7TtERFJNMhPEZmBCzHZ1WBbPVbx7e2mgbZPuuOogQbxev6ufmiIi6SOZCWIhMN3MJptZDkESWNC7kpnNBEqBl2KKHwMuMrNSMysFLgrLIlGcl82U8gKW1OsKQkRGjqQ9xeTuHWZ2I8Ev9kzgLndfZma3AXXu3p0srgLud3ePabvDzL5OkGQAbnP3HcmKNRGzq0t4eX2kIYiIDKmkJQgAd38EeKRX2dd6bd/aR9u7gLuSFtwAza4ezW8Xv822PfupLM6LOhwRkaRLlU7qlDc77IfQbSYRGSmUIBJ07LgSMkwd1SIycihBJCg/J5MZVUW6ghCREUMJYgBmV5fw+ubdxPSni4ikLSWIAZhdPZodzW3U72yJOhQRkaRTghiA7o7qpbrNJCIjgBLEABx9VBE5mRks3ayOahFJf0oQA5CblcnMsUUs3aQrCBFJf0oQAzS7uoQ3Nu/WHNUikvaUIAZo9vjRNLV2sH57c9ShiIgklRLEAJ08aTQAr7055JPbiYgMKSWIAZpaUUjpqGwWbtTAfSKS3pQgBsjMmDOpjEW6ghCRNKcEcRhqa0pZv72Z7Xtbow5FRCRplCAOwyk1pQDUbdRVhIikLyWIw3Dc+BJysjJY9Kb6IUQkfSlBHIbcrExOrB7NQl1BiEgaU4I4THNqSnlj825a2jqjDkVEJCmSmiDMbJ6ZrTKztWZ2cx91rjSz5Wa2zMzuiynvNLPF4bIgXtsonVJTSkeXs3iTxmUSkfSUtDmpzSwTuAO4EKgHFprZAndfHlNnOvBV4Ex332lmlTGHaHH3E5MV35GaM7EMgEVv7uD0qWMijkZEZPAl8wpiLrDW3de7extwPzC/V51PAne4+04Ad9+WxHgGVcmobGZUFaofQkTSVjITxHhgU8x2fVgWawYww8xeMLOXzWxezL48M6sLyy+P9wVmdn1Yp66hoWFwo09AbU0Zr725k04N3CciaSjqTuosYDpwHnA18GMzGx3um+TutcA1wH+a2dTejd39TnevdffaioqKoYr5gFNqSmlq7WDV1qYh/24RkWRLZoLYDEyI2a4Oy2LVAwvcvd3dNwCrCRIG7r45/FwPPAOclMRYD0vtpKAfok7vQ4hIGkpmglgITDezyWaWA1wF9H4a6bcEVw+YWTnBLaf1ZlZqZrkx5WcCy0kx1aX5jC3J45X1ShAikn6SliDcvQO4EXgMWAE86O7LzOw2M7ssrPYY0Ghmy4GngS+7eyNwDFBnZkvC8m/EPv2UKsyMM6aW8+K67ZpASETSTtIecwVw90eAR3qVfS1m3YEvhktsnReB45MZ22A5c9oYfvVaPcu37OG48SVRhyMiMmii7qQe9s6cVg7AC2u3RxyJiMjg6jdBmFmVmf23mf0x3J5lZh9PfmjDQ1VxHtMqC3lhXWPUoYiIDKpEriDuJugrGBdurwY+n6yAhqOzppXz6oZGWjs0LpOIpI9EEkS5uz8IdMGBzmf9JoxxxtQx7G/v4i9vaVwmEUkfiSSIZjMbAziAmZ0G7E5qVMPMaVPHkGHqhxCR9JJIgvgiwfsLU83sBeCnwGeTGtUwU5yXzezq0UoQIpJW+n3M1d1fM7NzgaMBA1a5e3vSIxtmzppWzg+fXUfT/naK8rKjDkdE5Igl8hTTRwnGQ5oDnAxcHZZJjDOmjaGzy/VWtYikjURelDslZj0PuAB4jeBWk4ROnlhKXnYGf167nffOqoo6HBGRI5bILaYe/Q3haKv3Jy2iYSovO5NTasrUDyEiaeNw3qRuBiYPdiDp4JzpFazZtpf6nfuiDkVE5Igl0gfxezNbEC5/AFYBv0l+aMPP+ccEM6Y+vXLYTIwnItKnRPog/j1mvQN4093rkxTPsDa1opDJ5QU8uWIbf3N6TdThiIgckUT6IJ4dikDSxfkzK7n3pTdpbu2gIDepg+WKiCRVn7eYzKzJzPbEWZrMbM9QBjmcXDCzkrbOLnVWi8iw12eCcPcidy+OsxS5e/FQBjmc1NaUUZSbxVPqhxCRYS7heyBmVknwHgQA7v5WUiIa5nKyMjhnRgVPrdxGV5eTkWFRhyQiclgSeYrpMjNbA2wAngU2An9MclzD2gXHVLKtqZVlb+tOnIgMX4m8B/F14DRgtbtPJniT+uVEDm5m88xslZmtNbOb+6hzpZktN7NlZnZfTPm1ZrYmXK5N5PtSxXlHV2IGf1r5TtShiIgctkQSRLu7NwIZZpbh7k8Dtf01MrNM4A7gEmAWwRhOs3rVmQ58FTjT3Y8lnIjIzMqAW4BTgbnALWZWmvgfK1plBTmcPLFU/RAiMqwlkiB2mVkh8BzwczP7DsHb1P2ZC6x19/Xu3kYwPMf8XnU+Cdzh7jsB3L37N+rFwBPuviPc9wQwL4HvTBnnz6xkaf1u3tmzP+pQREQOSyIJYj6wD/gC8CiwDnh/Au3GA5tituvDslgzgBlm9oKZvWxm8wbQFjO73szqzKyuoaEhgZCGzoXhgH2PL9dtJhEZnhJJEDcAY929w93vcffvhrecBkMWMB04D7ga+HE4GGBC3P1Od69199qKiopBCmlwTK8sZGpFAY8s3RJ1KCIihyWRBFEEPG5mz5vZjWaW6FjWm4EJMdvVYVmsemCBu7e7+wZgNUHCSKRtSjMz/mr2OF7Z0EhDU2vU4YiIDFi/CcLd/ynsQP4MMBZ41syeTODYC4HpZjbZzHKAqwimLo31W4KrB8ysnOCW03rgMeAiMysNO6cvCsuGlb86fixdDo8u2xp1KCIiAzaQ4b63AVuBRqCyv8ru3gHcSPCLfQXwoLsvM7PbzOyysNpjQKOZLQeeBr7s7o3uvoPg8dqF4XJbWDaszKgqZFplIQ8vfTvqUEREBszc/dAVzP43cCVQAfyS4Bf98iGIbUBqa2u9rq4u6jAOcvsTq/neU2t45e8voLIor/8GIiJDyMwWuXvcVxcSuYKYAHze3Y9191tTMTmksvfNHos7PPaGbjOJyPCSSB/EV9198VAEk45mVBUxvbKQP+hpJhEZZg5nylEZoEuPH8urG3ewTS/NicgwogQxBP4qvM2kp5lEZDhJZDTXAjPLCNdnhKO7Zic/tPQxo6qIGVWF/PYvw+pVDhEZ4RK5gngOyDOz8cDjwN8AdyczqHR0xcnVvPbWLtY17I06FBGRhCSSIMzd9wF/DfzA3T8EHJvcsNLPB04aT4bBrxbVRx2KiEhCEkoQZnY68BHg4bAsM3khpafK4jzOnVHBr1/bTGfXod89ERFJBYkkiM8TzNnwm/BN6CkEbz3LAH1wzgS27tnPC2u3Rx2KiEi/+p2T2t2fJZhqlLCzeru735TswNLRBcdUUpKfzUOL6jlnRmqNPisi0lsiTzHdZ2bFZlYAvAEsN7MvJz+09JOXncn8E8fx2LKt7G5pjzocEZFDSuQW0yx33wNcDvwRmEzwJJMchg/Oqaa1o4uH9Wa1iKS4RBJEdvjew+WEczcA6mU9TMePL2FGVSG/XLSp/8oiIhFKJEH8CNgIFADPmdkkYE8yg0pnZsaH5kzgL2/tYuVWnUYRSV2JDNb3XXcf7+6XeuBN4D1DEFva+uCcanKzMvjpS29GHYqISJ8S6aQuMbPbzawuXL5NcDUhh6m0IIf5J47jN69tVme1iKSsRG4x3QU0EUwadCXB7aX/SWZQI8FHT6+hpb1Tb1aLSMpKJEFMdfdb3H19uPwTMCXZgaW748aXcPLE0dz78pt06c1qEUlBiSSIFjM7q3vDzM4EWhI5uJnNM7NVZrbWzG6Os/86M2sws8Xh8omYfZ0x5QsS+b7h5tozatiwvZnn9Wa1iKSgft+kBj4F/NTMSsLtncC1/TUys0zgDuBCoB5YaGYL4kxZ+oC73xjnEC3ufmIC8Q1b8447ivLCHO59aSPn6s1qEUkxiTzFtMTdTwBmA7Pd/STg/ASOPRdYG96WagPuB+YfUbRpJjcrk6vnTuRPK7exace+qMMREekh4Rnl3H1P+EY1wBcTaDIeiH0brD4s6+0KM1tqZg+Z2YSY8rzwqamXzezyROMcbq45dSKZZtz1woaoQxER6eFwpxy1Qfr+3wM17j4beAK4J2bfJHevBa4B/tPMph4UhNn13Y/fNjQ0DFJIQ2tsST7zTxzP/a9uYkdzW9ThiIgccLgJIpHHbjYDsVcE1WHZuwdxb3T31nDzJ8CcmH2bw8/1wDPASQcF4X6nu9e6e21FxfC9h/+pc6fQ0t7JPS9ujDoUEZED+kwQZtZkZnviLE3AuASOvRCYbmaTzSwHuAro8TSSmY2N2bwMWBGWl5pZbrheDpwJ9O7cThvTq4q4cFYV97y0kebWjqjDEREBDpEg3L3I3YvjLEXunsg8Eh3AjcBjBL/4HwwnHLrNzC4Lq91kZsvMbAlwE3BdWH4MUBeWPw18I87TT2nl0+dNZde+du5fqEH8RCQ1mHt6vKRVW1vrdXV1UYdxRK668yXebNzHs19+DzlZh3v3T0QkcWa2KOzvPYh+C6WQT583jS279/PbxZv7rywikmRKECnknOnlHDuumB88vZb2zq6owxGREU4JIoWYGV+8cAYbG/fxkAbxE5GIKUGkmPNnVnLyxNF858k17G/vjDocERnBlCBSjJnx5YtnsnXPfn72siYUEpHoKEGkoNOnjuHs6eX84Jl17NV7ESISESWIFPWli45mR3Mbd/1ZYzSJSDSUIFLUCRNGc/GxVfz4ufU07m3tv4GIyCBTgkhhX774aFraO/n3x1dHHYqIjEBKEClsWmUR155Rw/0L3+KNzbujDkdERhgliBR30wXTKRuVw60LlpEuw6KIyPCgBJHiSvKz+cq8o6l7cycLlrwddTgiMoIoQQwDH5ozgePHl/Cvj6zUcOAiMmSUIIaBjAzj1stmsXXPfr77pzVRhyMiI4QSxDAxZ1IZV8+dwI+fX8/S+l1RhyMiI4ASxDBy8yXHUFGUy1ceWkpbh0Z7FZHkUoIYRkrys/nny49n5dYmfvTsuqjDEZE0pwQxzFw4q4r3zR7L955ay5p3mqIOR0TSmBLEMHTrZccyKjeTLz20VBMLiUjSJDVBmNk8M1tlZmvN7OY4+68zswYzWxwun4jZd62ZrQmXa5MZ53BTXpjLP19+HEs27dJTTSKSNFnJOrCZZQJ3ABcC9cBCM1vg7st7VX3A3W/s1bYMuAWoBRxYFLbdmax4h5v3zR7Hs6sa+P7TazlzWjmnTRkTdUgikmaSeQUxF1jr7uvdvQ24H5ifYNuLgSfcfUeYFJ4A5iUpzmHr1suOpWZMAV94YDG79rVFHY6IpJlkJojxwKaY7fqwrLcrzGypmT1kZhMG0tbMrjezOjOra2hoGKy4h42C3Cy+e9VJbN/bys2/el1jNYnIoIq6k/r3QI27zya4SrhnII3d/U53r3X32oqKiqQEmOqOry7hyxcfzaPLtnLXCxujDkdE0kgyE8RmYELMdnVYdoC7N7p792w4PwHmJNpW3vWJs6Zw0awq/t8jK3hx3faowxGRNJHMBLEQmG5mk80sB7gKWBBbwczGxmxeBqwI1x8DLjKzUjMrBS4KyySOjAzj9g+fyOTyAm687y/U79wXdUgikgaSliDcvQO4keAX+wrgQXdfZma3mdllYbWbzGyZmS0BbgKuC9vuAL5OkGQWAreFZdKHwtws7vybObR3dnHDvYtoaeuMOiQRGeYsXTo2a2trva6uLuowIvfUynf4+D11XHrcWL539UlkZFjUIYlICjOzRe5eG29f1J3UMsjOn1nFVy+ZycOvb+FfHlnRfwMRkT4k7UU5ic4nz57C27v2899/3sDYkjw+cfaUqEMSkWFICSINmRn/932z2Na0n39+eAVVxXm8/4RxUYclIsOMbjGlqcwM4/YrT2RuTRlffHAxf1rxTtQhicgwowSRxvKyM/nJdbXMGlvMp3/2Gk+v2hZ1SCIyjChBpLnivGx++renMuOoQm64dxHPrR55Q5KIyOFRghgBSkZlc+/fnsrUikI++dM6XUmISEKUIEaI0oIcfvbxuUyrLOST99Txu8UauUREDk0JYgQZU5jLL64/jdqaUj53/2LufmFD1CGJSApTghhhivOyuftjc7n42Cpu/f1y/u3RlXR1pcfb9CIyuJQgRqC87EzuuOZkrjl1Ij94Zh2f+tkimls7og5LRFKMEsQIlZWZwb9cfhy3vH8WT654hyt++KJGgRWRHpQgRjAz42NnTubuj81l864WLvv+C3oMVkQOUIIQzplRwW8/cyblhTlc+z+v8u3HV9HR2RV1WCISMSUIAWBqRSG/+8xZfGhONd97ai0f+ckrbNndEnVYIhIhJQg5ID8nk3/74Al8+0MnsLR+Nxf9x3P85i/1pMucISIyMEoQcpAr5lTzyOfOZkZVEV94YAmf/tlrbN/b2n9DEUkrShAS1+TyAh684XS+eslMnlq5jffe/iwPLtykdyZERpCkJggzm2dmq8xsrZndfIh6V5iZm1ltuF1jZi1mtjhc/iuZcUp8mRnGDedO5eGbzmJGZRFf+dVSPnznS6za2hR1aCIyBJKWIMwsE7gDuASYBVxtZrPi1CsCPge80mvXOnc/MVw+law4pX/Tq4p44IbT+NYHZ7N2214u/e7zfO13b7CjuS3q0EQkiZJ5BTEXWOvu6929DbgfmB+n3teBbwL7kxiLHCEz40O1E/jT353HNXMn8vNX3uLcbz3Nj55dx/72zqjDE5EkSGaCGA9sitmuD8sOMLOTgQnu/nCc9pPN7C9m9qyZnR3vC8zsejOrM7O6hga94DUUygpy+Prlx/HY58/mlJoy/vWPKzn3W09zz4sblShE0kxkndRmlgHcDvxdnN1bgInufhLwReA+MyvuXcnd73T3WnevraioSG7A0sO0yiLuuu4U7vvkqUwqK+CWBcs491tPc/cLG5QoRNJEMhPEZmBCzHZ1WNatCDgOeMbMNgKnAQvMrNbdW929EcDdFwHrgBlJjFUO0xlTy3nghtOCRDGmgFt/v/zAradd+9RHITKcWbJegjKzLGA1cAFBYlgIXOPuy/qo/wzwJXevM7MKYIe7d5rZFOB54Hh339HX99XW1npdXd1g/zFkgF5a18h3/7SGl9Y3kp+dyQdOHs/HzqhhelVR1KGJSBxmtsjda+Pty0rWl7p7h5ndCDwGZAJ3ufsyM7sNqHP3BYdofg5wm5m1A13Apw6VHCR1nD51DKdPHcPyt/dwz4sbeWhRPfe98hZnTy/nI6dO5PyZVeRk6fUbkeEgaVcQQ01XEKlpR3Mbv3j1Le596U227tlP6ahs5p84ng/VVnPsuJKowxMZ8Q51BaEEIUOio7OL59du56G6ep5Y/g5tnV0cM7aYy08cx6XHj2VC2aioQxQZkZQgJKXsbG7j90vf5qFF9Syt3w3A8eNLuOT4o7j0uLHUlBdEHKHIyKEEISlr0459/PGNLTzy+lYWb9oFwPTKQt4zs5LzZlRQW1OmPguRJFKCkGFh864WHn1jK0+v3MYrGxpp73QKcjI5c1o5Z08v59QpY5heWYiZRR2qSNpQgpBhp7m1gxfXNfLMqm08s6qBzbuCyYvKCnKYW1PGqVPKmDu5jGOOKiYjQwlD5HBF8piryJEoyM3iwllVXDirCndn044WXt7QyCvrd/DKhkYeXbYVgOK8LE6YMJoTqkczu7qE2dWjOaokL+LoRdKDEoSkPDNj4phRTBwziitrg5fzN+9q4ZX1jby6YQdL6nfzw2fX0RnOVVFZlMvs6tEcP76EmWOLOLqqiIllo3SlITJAusUkaaGlrZPlW3aztD5YltTvYn1D84H9+dmZTK8q5OiqIo4+qohplYVMLi9g/Oh8sjLVCS4jl24xSdrLz8lkzqQy5kwqO1DW3NrB6neaWP1OE6u27mX1O008vaqBXy6qP1AnK8OYUDaKmjGjmDSmgMnlBdSUF1AzZhRjS/L1BJWMaEoQkrYKcrM4aWIpJ00s7VHeuLeVdQ3NbGxsZuP27s99vLJhB/va3h2J1gwqCnMZNzqfcaPzGFeSH67nM350PlXFuZQV5OgKRNKWEoSMOGMKcxlTmMvcyWU9yt2dhqZWNjbuY2NjM2/vagmX/azc2sRTK7exv72rRxszKBuVQ0VRLhVFuZQXBp8VhbmUF+VQUZhHWUEOo0dlUzoqh7zsDD2mK8OGEoRIyMyoLM6jsjjvoOQBQQLZua+dt3e1sHlXC9uaWmkIl+17g8/1Dc1s39tKa0dXnG+AnKwMRudnM3pUNqPzg8QRLDmUhOVFedkU5WZRkJtFYW4WRXnvruuWlwwlJQiRBJkZZQU5lBXkcNz4vgcadHeaWjvY3tTKtqZWdja3saulnV372tnV0sau5vBzXztv7djHkvo2du5rp62PpBIrJzODwrwsCnIzKczNpjA3k8IwmeRlZ5KfnUledgb52Znkhtv5OXHKsjN71M/OzCAnK1iyMkxXOQIoQYgMOjOjOC+b4rxsplQUJtxuf3snO/e1sXd/B02tHTSHS9P+4HNvawd7WzvZ29pOc2tnsL2/g8bmNt7csY/W9i5a2jtpaetkf0cnR/KAYk5WBjlh0sjOtPDz3bJ39/XczsowsjKNzAwjKyMj/LSYz4yY/e9+ZmX2rhuznRl+mpGRYWSYkWHBec7MCNYzzLDws7vM7N26GQfa9qob1rEMeta1nnVHasJUghBJEXnZmYwtyYdBGAXd3Wnt6Ho3abR3sr/7M0wgLW1dB8rbO7to6+g68NnW6eFnJ+0dTltnV7DE1Gnv7KK5tSOs20lbZxednU5Hl9PZFfvZRWeX0945fB+p7044RtDvZBjhfwe27cB2UI/Y7d77wnb0aHfwcbrr9fcds8aV8L2rTxr0P7cShEgaMjPywttIJWRHHc4BXTGJo72rd0Lp6plYOg8u73LHHbo82Ne93tX92RWz3l/dXvXdoTO2Xbiv0x2PKXcIP4ONYPvgfd1XcO7es82BdcI6YduYdn1+R4+24dEcJpblJ+XnpQQhIkMmI8PICd9ozycz4mikP3okQkRE4kpqgjCzeWa2yszWmjwmyyoAAAivSURBVNnNh6h3hZm5mdXGlH01bLfKzC5OZpwiInKwpN1iMrNM4A7gQqAeWGhmC9x9ea96RcDngFdiymYBVwHHAuOAJ81shrt3IiIiQyKZVxBzgbXuvt7d24D7gflx6n0d+CawP6ZsPnC/u7e6+wZgbXg8EREZIslMEOOBTTHb9WHZAWZ2MjDB3R8eaFsREUmuyDqpzSwDuB34uyM4xvVmVmdmdQ0NDYMXnIiIJDVBbAYmxGxXh2XdioDjgGfMbCNwGrAg7Kjury0A7n6nu9e6e21FRcUghy8iMrIlM0EsBKab2WQzyyHodF7QvdPdd7t7ubvXuHsN8DJwmbvXhfWuMrNcM5sMTAdeTWKsIiLSS9KeYnL3DjO7EXgMyATucvdlZnYbUOfuCw7RdpmZPQgsBzqAz/T3BNOiRYu2m9mbRxByObD9CNoPFcU5uBTn4FKcg2so4pzU1460mXL0SJlZXV/T7qUSxTm4FOfgUpyDK+o49Sa1iIjEpQQhIiJxKUG8686oA0iQ4hxcinNwKc7BFWmc6oMQEZG4dAUhIiJxKUGIiEhcIz5BJDok+VAzswlm9rSZLTezZWb2ubD8VjPbbGaLw+XSFIh1o5m9HsZTF5aVmdkTZrYm/CyNOMajY87ZYjPbY2afT5XzaWZ3mdk2M3sjpizuObTAd8O/s0vDMc2iivFbZrYyjOM3ZjY6LK8xs5aY8/pfQxFjP7H2+bOOanqBPuJ8ICbGjWa2OCwf+nPq4XR6I3EheIFvHTAFyAGWALOijiuMbSxwcrheBKwGZgG3Al+KOr5esW4EynuV/Rtwc7h+M/DNqOPs9XPfSvCCUEqcT+Ac4GTgjf7OIXAp8EeC6YhPA16JMMaLgKxw/ZsxMdbE1kuR8xn3Zx3+f7UEyAUmh78TMqOKs9f+bwNfi+qcjvQriESHJB9y7r7F3V8L15uAFQyvEW3nA/eE6/cAl0cYS28XAOvc/UjevB9U7v4csKNXcV/ncD7wUw+8DIw2s7FRxOjuj7t7R7j5MsG4aZHr43z2JbLpBQ4Vp5kZcCXwi6GIJZ6RniCGxbDiZlYDnMS7kyrdGF7S3xX1rZuQA4+b2SIzuz4sq3L3LeH6VqAqmtDiuoqe/9Ol2vns1tc5TNW/t39LcGXTbbKZ/cXMnjWzs6MKqpd4P+tUPZ9nA++4+5qYsiE9pyM9QaQ8MysEfgV83t33AD8EpgInAlsILkGjdpa7nwxcAnzGzM6J3enB9XFKPE9twcCRlwG/DItS8XweJJXOYTxm9g8E46b9PCzaAkx095OALwL3mVlxVPGFhsXPOsbV9PyHzJCf05GeIBIaVjwqZpZNkBx+7u6/BnD3d9y90927gB+TAjPtufvm8HMb8BuCmN7pvu0Rfm6LLsIeLgFec/d3IDXPZ4y+zmFK/b01s+uA9wEfCRMZ4e2axnB9EcF9/RlRxRjG0dfPOqXOJ4CZZQF/DTzQXRbFOR3pCeKQQ5JHKbz/+N/ACne/PaY89l7zB4A3ercdSmZWYMG84phZAUGn5RsE5/HasNq1wO+iifAgPf5Vlmrns5e+zuEC4KPh00ynAbtjbkUNKTObB3yFYKj+fTHlFRbMS4+ZTSEYsn99FDHGxNTXzzoVpxd4L7DS3eu7CyI5p0PZI56KC8ETIasJsvE/RB1PTFxnEdxSWAosDpdLgXuB18PyBcDYiOOcQvAEyBJgWfc5BMYAfwLWAE8CZSlwTguARqAkpiwlzidB0toCtBPcA/94X+eQ4OmlO8K/s68DtRHGuJbg/n3339H/CuteEf59WAy8Brw/Bc5nnz9r4B/C87kKuCTKOMPyu4FP9ao75OdUQ22IiEhcI/0Wk4iI9EEJQkRE4lKCEBGRuJQgREQkLiUIERGJSwlChj0z2xt+1pjZNYN87L/vtf3iYB5/sJnZdWb2/ajjkPSgBCHppAYYUIII31g9lB4Jwt3PGGBMw0r3i1gioAQh6eUbwNnhWPlfMLPMcL6CheEAbTcAmNl5Zva8mS0Alodlvw0HG1zWPeCgmX0DyA+P9/OwrPtqxcJjv2HBXBgfjjn2M2b2kAXzJPw8fCu+h7DON83sVTNb3T3wWu8rADP7g5md1/3d4XcuM7MnzWxueJz1ZnZZzOEnhOVrzOyWmGP9r/D7FpvZj2Leyt1rZt82syXA6YP1w5A0MJRvN2rRkowF2Bt+ngf8Iab8euAfw/VcoI5gvP/zgGZgckzd7reU8wmGYBgTe+w433UF8ATB3BJVwFsEc3icB+wmGM8nA3iJYDDD3jE/A3w7XL8UeDJcvw74fky9PwDnhetO+JYvwZhXjwPZwAnA4pj2Wwjewu7+s9QCxwC/B7LDej8APhpz3Cuj/jlqSb2lv8trkeHsImC2mX0w3C4hGL+mDXjVg7H/u91kZh8I1yeE9RoPceyzgF+4eyfBoHrPAqcAe8Jj1wNYMBtYDfDnOMf4dfi5KKzTnzbg0XD9daDV3dvN7PVe7Z/wcFA3M/t1GGsHMAdYGF7Q5PPu4H+dBINCivSgBCHpzIDPuvtjPQqDWzbNvbbfC5zu7vvM7Bkg7wi+tzVmvZO+/z9rjVOng563fmPjaHf37rFxurrbu3tXr76U3uPnOMG5uMfdvxonjv1hohPpQX0Qkk6aCKZn7fYY8Olw2HTMbEY44mxvJcDOMDnMJJjGs1t7d/tengc+HPZzVBBMHTkYI4BuBE40swwzm8DhDT9+oQXzWecTzEL3AsGgfx80s0o4MN/1pEGIV9KYriAknSwFOsPO1ruB7xDcenkt7ChuIP7Up48CnzKzFQSjeb4cs+9OYKmZvebuH4kp/w1Bh+4Sgn+hf8Xdt4YJ5ki8AGwg6DxfQTBq50C9SnDLqBr4mbvXAZjZPxLM/JdBMHroZ4CUmXZVUo9GcxURkbh0i0lEROJSghARkbiUIEREJC4lCBERiUsJQkRE4lKCEBGRuJQgREQkrv8PGkHyakstdu4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y_predict = model_Twolayer(test_X.float())\n",
        "output_test = (test_y_predict>0.5).float()\n",
        "test_Twolayer = test_y.unsqueeze(1)\n",
        "correct_Twolayer = (output_test == test_Twolayer).float().sum()\n",
        "print(correct_Twolayer)\n",
        "correct_Twolayer = correct_Twolayer / test_X.shape[0]\n",
        "print(\"test acc is %f\"%(correct_Twolayer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0xmljJWKHD7",
        "outputId": "b0d7303b-4d0e-4f22-f2ae-a6f9c6f177bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(48.)\n",
            "test acc is 1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6zIVjdqZMFOK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}